# RAG 简介

RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合检索和生成的LLM应用技术。它通过在生成回答前检索相关文档或知识，为LLM提供额外的上下文信息，从而提高回答的准确性和可靠性。

## RAG的工作原理

1. **检索阶段**：根据用户查询，从文档库或知识库中检索相关的文档片段
2. **增强阶段**：将检索到的文档片段与用户查询结合，形成增强的输入
3. **生成阶段**：LLM基于增强的输入生成回答

## RAG的优势

- **知识更新**：无需重新训练模型，通过更新文档库即可更新知识
- **事实准确性**：减少模型生成幻觉（hallucination）的可能性
- **领域适应性**：可针对特定领域的文档进行检索，提高领域问题的回答质量
- **可解释性**：可以引用检索到的文档片段，增强回答的可解释性

## 常见应用场景

- 问答系统：针对特定领域的知识问答
- 文档摘要：基于检索到的文档生成摘要
- 信息抽取：从大量文档中抽取特定信息并回答问题
- 客服系统：结合企业知识库，提供更准确的客户服务

## 典型框架

- LangChain：提供RAG相关的工具和组件
- LlamaIndex：专注于构建RAG应用的框架
- Haystack：开源的NLP框架，支持RAG功能
- DeepLake：支持向量存储和RAG应用的框架